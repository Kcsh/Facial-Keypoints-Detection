{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_data(img, landmarks, axis):\n",
    "    \n",
    "    axis.imshow(np.squeeze(img), cmap='gray') \n",
    "    landmarks = landmarks * 48 + 48 \n",
    "    axis.scatter(landmarks[0::2],\n",
    "        landmarks[1::2],\n",
    "        marker='o',\n",
    "        c='c',\n",
    "        s=40)\n",
    "\n",
    "def plot_keypoints(img_path,\n",
    "                  face_cascade=cv2.CascadeClassifier('cv haarcascade/haarcascade_frontalface_alt.xml'),\n",
    "                  model_path='my_model.h5'):\n",
    "    # function that plots keypoints on arbitrary image containing human\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[])\n",
    "    ax.imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        plt.title('no faces detected')\n",
    "    elif len(faces) > 1:\n",
    "        plt.title('More than one faces detected')\n",
    "        for (x,y,w,h) in faces:\n",
    "            rectangle = cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "            ax.imshow(cv2.cvtColor(rectangle, cv2.COLOR_BGR2RGB))\n",
    "    elif len(faces) == 1:\n",
    "        plt.title('Only one face detected')\n",
    "        x,y,w,h = faces[0]\n",
    "        bgr_crop = img[y:y+h, x:x+w]\n",
    "        orig_shape_crop = bgr_crop.shape\n",
    "        gray_crop = cv2.cvtColor(bgr_crop, cv2.COLOR_BGR2GRAY)\n",
    "        resize_gray_crop = cv2.resize(gray_crop, (96, 96)) / 255.\n",
    "        model = load_model(model_path)\n",
    "        landmarks = np.squeeze(model.predict(\n",
    "            np.expand_dims(np.expand_dims(resize_gray_crop, axis=-1), axis=0)))\n",
    "        ax.scatter(((landmarks[0::2] * 48 + 48)*orig_shape_crop[0]/96)+x,\n",
    "                   ((landmarks[1::2] * 48 + 48)*orig_shape_crop[1]/96)+y,\n",
    "                   marker='o', c='c', s=40)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
